{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7cd037-8962-46c2-a17c-f45fa6ce8dcb",
   "metadata": {},
   "source": [
    "# We show how to run rigid and/or piecewise rigid motion correction on the demoMovie.tif dataset found in the datasets folder of this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229191b2-91cf-4e04-9c06-f54094ab1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jnormcorre import motion_correction\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "#Things that the mc function was missing -- put this in a better location\n",
    "import os\n",
    "import tifffile\n",
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be2447-ab63-4a1f-aa7e-777c0376f9cf",
   "metadata": {},
   "source": [
    "# Specify dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707a21c3-103a-40d5-ba6d-b706ae88ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../datasets/demoMovie.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d48ea7-ebed-4ba7-9c8a-eb6efb899f4c",
   "metadata": {},
   "source": [
    "# Run Motion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5315859a-782e-4c86-bcdd-1464797d74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(filename):\n",
    "    import tifffile\n",
    "    with tifffile.TiffFile(filename) as tffl:\n",
    "      num_frames = len(tffl.pages)\n",
    "      for page in tffl.pages[0:1]:\n",
    "          image = page.asarray()\n",
    "          x, y = page.shape\n",
    "    return (x,y,num_frames)\n",
    "\n",
    "def resolve_dataformats(filename):\n",
    "    '''\n",
    "    Function for managing bad data formats (such as single-page tif files) which are tough to load. Resolves these issues by loading the data into memmap format and then saving the data (in small batches) into a better format\n",
    "    Input: \n",
    "        filename: str. String describing the full filepath of the datafile\n",
    "    Returns: \n",
    "        file_output: list of strings. In this list, each string is a filename. These files, taken together, form the entire dataset\n",
    "    '''\n",
    "    _, extension = os.path.splitext(filename)[:2]\n",
    "    if extension in ['.tif', '.tiff', '.btf']:  # load tif file\n",
    "        with tifffile.TiffFile(filename) as tffl:\n",
    "            multi_page = True if tffl.series[0].shape[0] > 1 else False\n",
    "            if len(tffl.pages) == 1:\n",
    "                display(\"Data is saved as single page tiff file. We will re-save data as sequence of smaller tifs to improve performance, but this will take time. To avoid this issue, save your data as multi-page tiff files\")\n",
    "                file_output = chunk_singlepage_data(filename)\n",
    "                return file_output\n",
    "\n",
    "    file_output = [filename]\n",
    "    return file_output\n",
    "\n",
    "def motion_correct(filename,\n",
    "                   outdir,\n",
    "                   dxy = (2., 2.),\n",
    "                   max_shift_um = (12., 12.),\n",
    "                   max_deviation_rigid = 3,\n",
    "                   patch_motion_um = (100., 100.),\n",
    "                   overlaps = (24, 24),\n",
    "                   border_nan= 'copy',\n",
    "                   niter_rig = 4,\n",
    "                   splits=200,\n",
    "                   pw_rigid = True,\n",
    "                   gSig_filt=None,\n",
    "                   save_movie=True,\n",
    "                   dtype='int16',\n",
    "                   sketch_template=False,\n",
    "                   **params):\n",
    "    \"\"\"\n",
    "    Runs motion correction from caiman on the input dataset with the\n",
    "    option to process the same dataset in multiple passes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        Full path + name for destination of output config file.\n",
    "    outdir : string\n",
    "        Full path to location where outputs should be written.\n",
    "    dxy: tuple (2 elements)\n",
    "        Spatial resolution in x and y in (um per pixel)\n",
    "    max_shift_um: tuple (2 elements)\n",
    "        Maximum shift in um\n",
    "    max_deviation_rigid: int\n",
    "        Maximum deviation allowed for patch with respect to rigid shifts\n",
    "    patch_motion_um: \n",
    "        Patch size for non rigid correction in um\n",
    "    overlaps:\n",
    "        Overlap between patches\n",
    "    border_nan: \n",
    "        See linked caiman docs for details\n",
    "    niter_rig: int\n",
    "        Number of passes of rigid motion correction (used to estimate template)\n",
    "    splits: int\n",
    "        We divide the registration into chunks (temporally). Splits = number of frames in each chunk. So splits = 200 means we break the data into chunks, each containing ~200 frames.\n",
    "    pw_rigid: boolean \n",
    "        Indicates whether or not to run piecewise rigid motion correction\n",
    "    devel: boolean\n",
    "        Indicates whether this code is run in development mode. If in development mode, the original data is not deleted.\n",
    "    Returns\n",
    "    -------\n",
    "    None :\n",
    "    \"\"\"\n",
    "\n",
    "    from jnormcorre.utils.movies import load\n",
    "    from jnormcorre import motion_correction\n",
    "    import math\n",
    "\n",
    "    # Iteratively Run MC On Input File\n",
    "    display(\"Running motion correction...\")\n",
    "    target = resolve_dataformats(filename)\n",
    "\n",
    "    total_frames_firstfile = get_shape(target[0])[2]\n",
    "    splits = math.ceil(total_frames_firstfile / splits)\n",
    "    display(\"Number of chunks is {}\".format(splits))\n",
    "\n",
    "    ## TODO: Eliminate this convention where we include the default parameters both in the function signature above and here\n",
    "    # Default MC_dict\n",
    "    mc_dict = {\n",
    "    'max_deviation_rigid': 3,           # maximum deviation between rigid and non-rigid\n",
    "    'max_shifts': (6, 6),               # maximum shifts per dimension (in pixels)\n",
    "    'min_mov': -5,                      # minimum value of movie\n",
    "    'niter_rig': 4,                     # number of iterations rigid motion correction\n",
    "    'niter_els': 1,                     # number of iterations of piecewise rigid motion correction\n",
    "    'nonneg_movie': True,               # flag for producing a non-negative movie\n",
    "    'num_splits_to_process_els': None,  # The number of splits of the data which we use to estimate the template for the rigid motion correction. If none, we look at entire dataset.\n",
    "    'num_splits_to_process_rig': None,  # The number of splits of the data which we use to estimate the template for pwrigid motion correction. If none, we look at entire dataset.\n",
    "    'overlaps': (32, 32),               # overlap between patches in pw-rigid motion correction\n",
    "    'pw_rigid': False,                  # flag for performing pw-rigid motion correction\n",
    "    'splits_els': 14,                   # number of splits across time for pw-rigid registration\n",
    "    'splits_rig': 14,                   # number of splits across time for rigid registration\n",
    "    'strides': (96, 96),                # how often to start a new patch in pw-rigid registration\n",
    "    'upsample_factor_grid': 4,          # motion field upsampling factor during FFT shifts\n",
    "    'indices': (slice(None), slice(None)),  # part of FOV to be corrected\n",
    "    'gSig_filt': None\n",
    "}\n",
    "\n",
    "    max_shifts = [int(a/b) for a, b in zip(max_shift_um, dxy)]\n",
    "    strides = tuple([int(a/b) for a, b in zip(patch_motion_um, dxy)])\n",
    "    \n",
    "    mc_dict['pw_rigid']= pw_rigid\n",
    "    mc_dict['strides'] = strides\n",
    "    mc_dict['overlaps'] = overlaps\n",
    "    mc_dict['max_deviation_rigid'] = max_deviation_rigid\n",
    "\n",
    "    #Add these as formal parameters\n",
    "    # mc_dict['niter_rig'] = niter_rig\n",
    "    # mc_dict['niter_els'] = niter_els\n",
    "    if sketch_template:\n",
    "        mc_dict['num_splits_to_process_els'] = 5\n",
    "        mc_dict['num_splits_to_process_rig'] = 5\n",
    "    mc_dict['gSig_filt'] = gSig_filt\n",
    "    mc_dict['max_shifts'] = max_shifts\n",
    "    mc_dict['splits_els'] = splits\n",
    "    mc_dict['splits_rig'] = splits\n",
    "\n",
    "    corrector = motion_correction.MotionCorrect(target, **mc_dict)\n",
    "\n",
    "    # Run MC, Always Saving Non-Final Outputs For Use In Next Iteration\n",
    "    corrector_obj, target_file = corrector.motion_correct(\n",
    "        save_movie=save_movie\n",
    "    )\n",
    "\n",
    "    display(\"Motion correction completed.\")\n",
    "\n",
    "    # Save Frame-wise Shifts\n",
    "    display(f\"Saving computed shifts to ({outdir})...\")\n",
    "    np.savez(os.path.join(outdir, \"shifts.npz\"),\n",
    "             shifts_rig=corrector.shifts_rig,\n",
    "             x_shifts_els=corrector.x_shifts_els if pw_rigid else None,\n",
    "             y_shifts_els=corrector.y_shifts_els if pw_rigid else None)\n",
    "    display('Shifts saved as \"shifts.npz\".')\n",
    "\n",
    "    corrector_obj.batching=10 ##Long term need to avoid this...\n",
    "    return corrector_obj, target_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4a9eb2-94e9-4e1a-861e-5927467f8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj, registered_filename = motion_correct(filename, \".\", sketch_template = True, pw_rigid = True, save_movie=True, overlaps=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219f77f-ebf9-4287-9873-d481cd87b3b2",
   "metadata": {},
   "source": [
    "# Generate Visualization (Run this if you have used save_movie = True to save out motion corrected movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8619717-fab6-49ad-8332-6580451f6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_correction_diagnostic(original_file, registered_file, frame_list = None):\n",
    "    if frame_list is None:\n",
    "        original_movie = tifffile.imread(original_file).transpose(1,2,0)\n",
    "        registered_movie = tifffile.imread(registered_file).transpose(1,2,0)\n",
    "    else:\n",
    "        original_movie = tifffile.imread(original_file, key=frame_list).transpose(1,2,0)\n",
    "        registered_movie = tifffile.imread(registered_file, key=frame_list).transpose(1,2,0)\n",
    "    d1, d2, T = original_movie.shape\n",
    "    display_movie = np.zeros((d1, d2*2, T), dtype=np.float32)\n",
    "    display_movie[:, :d2, :] = original_movie\n",
    "    display_movie[:, d2:, :] = registered_movie\n",
    "    \n",
    "    return display_movie\n",
    "\n",
    "display_movie = motion_correction_diagnostic(filename, registered_filename)\n",
    "\n",
    "tifffile.imwrite(\"diagnostic.tiff\", display_movie.transpose(2, 0, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
